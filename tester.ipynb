{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\anaconda3\\envs\\env1\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from UITws_v1 import UITws_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakenewsClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, dropout_rate=0.3):\n",
    "        super(FakenewsClassifier, self).__init__()\n",
    "        # Khởi tạo phoBERT\n",
    "        self.bert = AutoModel.from_pretrained(\"vinai/phobert-base\")\n",
    "\n",
    "        # Classifier network\n",
    "        self.d1 = nn.Dropout(p=dropout_rate)\n",
    "        self.fc1 = nn.Linear(self.bert.config.hidden_size, 64)\n",
    "        self.bn1 = nn.LayerNorm(64)\n",
    "        self.d2 = nn.Dropout(p=dropout_rate)\n",
    "        self.fc2 = nn.Linear(64, n_classes)\n",
    "        \n",
    "        # Khởi tạo trọng số theo normal\n",
    "        nn.init.normal_(self.fc1.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc1.bias, 0)\n",
    "        nn.init.normal_(self.fc2.weight, std=0.02)\n",
    "        nn.init.normal_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        last_hidden_state, output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=False,\n",
    "        )\n",
    "\n",
    "        x = self.d1(output)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm load mô hình\n",
    "def load_model():\n",
    "    # Xác định đường dẫn\n",
    "    model_path = \"./checkpoints/PhoBERT_1024.pth\"\n",
    "    \n",
    "    # Xác định thiết bị tính toán\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    # Khởi tạo instance model\n",
    "    model = FakenewsClassifier(n_classes=3, dropout_rate=0.3)\n",
    "    \n",
    "    # Chuyển model vào thiết bị tính toán\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Load model\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm load tokenizer\n",
    "def load_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm segmentation words\n",
    "def segmentation_words(text: str):\n",
    "    uitws_v1 = UITws_v1('./checkpoints/base_sep.pkl')\n",
    "    return uitws_v1.segment(texts=[text],\n",
    "                            pre_tokenized=True,\n",
    "                            batch_size=256)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuyển dữ liệu đầu vào thành dữ liệu mô hình có thể hiểu được\n",
    "def convert_data(text:str, tokenizer: AutoTokenizer):\n",
    "    # Xác định các thông số\n",
    "    fix_len = 1024\n",
    "    max_len = 256\n",
    "    stride = 255\n",
    "    \n",
    "    # Segmentation words\n",
    "    text = segmentation_words(text)\n",
    "    \n",
    "    # Chứa các sub-tokenizer của content\n",
    "    encoding_texts = []\n",
    "    \n",
    "    # Bắt đầu thực hiện các sub-token\n",
    "    start = 0\n",
    "    \n",
    "    # Hiển thị độ dài của câu\n",
    "    print(f'### Len of text: {len(text.split())} ###')\n",
    "    while start < fix_len:\n",
    "        end = min(start + max_len, fix_len)\n",
    "            \n",
    "        # Lấy phân đoạn của văn bản từ `start` đến `end`\n",
    "        segment = \" \".join(text.split()[start:end])\n",
    "        \n",
    "        print(f'=>start: {start}-end: {end}')\n",
    "        print(f'=>segment: {segment}')\n",
    "        \n",
    "        # Tiến hành tokenizer\n",
    "        encoding_text = tokenizer.encode_plus(\n",
    "        segment,\n",
    "        truncation=True,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        # Thêm vào danh sách chứa các sub-tokenizer của content\n",
    "        encoding_texts.append(encoding_text)\n",
    "        \n",
    "        print(\"-----------\")\n",
    "        \n",
    "        # Di chuyển chỉ số bắt đầu dựa trên stride\n",
    "        start += stride\n",
    "        \n",
    "        # Kiểm tra điều kiện\n",
    "        # if start >= len(text.split()):\n",
    "        #     break\n",
    "        \n",
    "    # Flatten encoding context\n",
    "    for encoding_text in encoding_texts:\n",
    "        encoding_text['input_ids'] = encoding_text['input_ids'].flatten()\n",
    "        encoding_text['attention_mask'] = encoding_text['attention_mask'].flatten()\n",
    "    \n",
    "        \n",
    "    # Trả về kết quả\n",
    "    return {\n",
    "        'encoding_texts': encoding_texts, # danh sách (input_ids, attention_mask)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm dự đoán kết quả\n",
    "def predict(text: str, model:FakenewsClassifier, tokenizer: AutoTokenizer):\n",
    "    # Convert data\n",
    "    encoding_texts = convert_data(text, tokenizer)['encoding_texts']\n",
    "    print(f'### Len encoding texts: {len(encoding_texts)} ###')\n",
    "    \n",
    "    # Xác định thiết bị tính toán\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    \n",
    "    # Biến lưu trữ tổng của outputs_text\n",
    "    total_outputs_text = None\n",
    "    num_sub_texts = 0\n",
    "    \n",
    "    # Duyệt qua từng sub-text trong texts\n",
    "    for idx, encoding_text in enumerate(encoding_texts):\n",
    "        print(f'#idx: {idx}')\n",
    "        \n",
    "        encoding_text_input_ids = encoding_text['input_ids'].to(device).unsqueeze(0)\n",
    "        encoding_text_attention_masks = encoding_text['attention_mask'].to(device).unsqueeze(0)\n",
    "             \n",
    "        print(f'=>Encoding_text_input_ids: {encoding_text_input_ids.shape}')\n",
    "        print(f'=>Encoding_text_attention_masks: {encoding_text_attention_masks.shape}')\n",
    "        \n",
    "        # Kiểm tra nếu input_ids toàn là padding token và attention_mask chủ yếu là 0\n",
    "        if torch.sum(encoding_text_attention_masks) <= 2:\n",
    "            print(f\"Bỏ qua sub-text tại vị trí {idx} vì input_ids toàn padding và attention_mask chủ yếu là 0\")\n",
    "            continue  # Bỏ qua sub-text này\n",
    "        \n",
    "        # Không đạo hàm\n",
    "        with torch.no_grad():\n",
    "            # Dự đoán cho sub-text\n",
    "            outputs_text = model(encoding_text_input_ids, attention_mask=encoding_text_attention_masks)\n",
    "            print(f'Dự đoán thành công')\n",
    "            \n",
    "            # Cộng dồn kết quả đầu ra\n",
    "            if total_outputs_text is None:\n",
    "                total_outputs_text = outputs_text\n",
    "            else:\n",
    "                total_outputs_text += outputs_text\n",
    "                \n",
    "            num_sub_texts += 1\n",
    "        \n",
    "    # Tính trung bình cộng của outputs_text\n",
    "    average_outputs_text = total_outputs_text / num_sub_texts\n",
    "\n",
    "    # Áp dụng softmax để chuyển logits thành xác suất\n",
    "    probabilities_softmax = torch.nn.functional.softmax(average_outputs_text, dim=-1)\n",
    "    \n",
    "    print(f'average_outputs_text: {probabilities_softmax}, shape: {probabilities_softmax.shape}')\n",
    "    \n",
    "    \n",
    "    # Trả về kết quả\n",
    "    probabilities = {\n",
    "    \"Thật\": probabilities_softmax[0][0].item(),\n",
    "    \"Giả do con người\": probabilities_softmax[0][1].item(),\n",
    "    \"Giả do AI\": probabilities_softmax[0][2].item()\n",
    "    }\n",
    "        \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo mô hình\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo tokenizer\n",
    "tokenizer = load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ACER\\anaconda3\\envs\\env1\\lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LinearSVC from version 1.5.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Len of text: 478 ###\n",
      "=>start: 0-end: 256\n",
      "=>segment: 23 9, 2010 kính gửi thủ_tướng nguyễn dũng cộng_hoà xã_hội chủ nghiã việt nam đại_sứ việt nam 1233 20th street, nw, suite 400 washington, dc 20036 thưa thủ tướng, mấy tuần cầm_quyền việt nam bắt giam vận_động dân chủ. giáo_sư_phạm minh hoàng, mục_sư dương kim khải, trần thị thuý nguyễn thành_tâm bắt giam đòi thay_đổi dân_chủ ôn_hoà thực_thi_nhân_quyền tham_gia hoạt_động trị tư thành_viên tổ_chức tranh_đấu dân_chủ đảng việt tân. giam lý nêu phi_lý thể chấp được. việt nam ký tuyên_ngôn quốc_tế nhân_quyền cầm_quyền việt nam tiếp_tục bắt sách_nhiễu trí thức, vị lãnh_đạo tôn_giáo_dân_chủ ôn_hoà quan tâm. dân_biểu quốc_hội hỗ_trợ rộng quan_hệ song_phương quyền tiếp_tục bóp_nghẹt thô_bạo quyền bày_tỏ bất_đồng kiến ôn_hoà dân nói, báo chí, mạng internet. tham_gia hoạt_động tranh_đấu ôn_hoà tội hình sự, quyền việt nam gán nhãn_hiệu bất hợp_pháp phi lý. cầm_quyền việt nam tiếp_tục đàn_áp dân quan tâm. bắt giam giáo_sư_phạm minh hoàng phản_đối khai_thác quặng mỏ bô-xít tây_nguyên viết đăng trang blog vô lý. quyền bạo_lực đối nguyễn thành_tâm trần thị thuý giúp nông_dân đòi công_xã_hội thể chấp nhận. kinh_hãi việt nam mục_sư dương kim khải tội_nhân ta thực_thi quyền tôn_giáo áp_dụng răn dậy tôn_giáo sống hàng giúp_đỡ nông_dân cướp ruộng_đất khiếu nại. cầm_quyền việt nam tiếp_tục biến quyền ngôn luận, quyền phát biểu, quyền hội_họp quyền tôn_giáo thành tội hình_thể chấp được. thể tiếp_tục thành_viên thực cộng_đồng giới, cầm_quyền việt nam ngưng sách_nhiễu đàn_áp dân phát_biểu ôn_hoà tham_gia hoạt_động trị. dân_biểu quốc_hội quan_tâm dạn thách_đố cầm_quyền việt nam phép tất công_dân_quyền phát_biểu phép tham_gia sinh_hoạt đấu tranh. kêu_gọi cầm_quyền việt nam\n",
      "-----------\n",
      "=>start: 255-end: 511\n",
      "=>segment: nam lập_tức ngừng sách_nhiễu dân thả tù_nhân trị hiện giam phản_đối quyết_định cầm quyền. trân trọng, loretta sanchez dân_biểu quốc_hội joseph dân_biểu quốc_hội zoe lofgren dân_biểu quốc_hội dan burton dân_biểu quốc_hội gerald connolly dân_biểu quốc_hội daniel lungren dân_biểu quốc_hội david wu dân_biểu quốc_hội john culbertson dân_biểu quốc_hội judy chu dân_biểu quốc_hội james mcgovern dân_biểu quốc hội. cc: trưởng ngoại_giao hillary rodham clinton giới_chức việt nam tuyến đường_sắt tốc nối hà nội sài gòn tầm quan_trọng chiến_lược dự_đoán lợi_ích to kinh_tế xã hội, kiến băn_khoăn chi phí, khả_thi mặt thương_mại tác_động hạn_chế kinh tế. tù nghìn_thu ngoài. đi tù nghĩa câu ấy. nhà, hàng trăm em, bè ta mòn_mỏi tù. mong tiếp_tục đồng_hành giúp_đỡ tù_nhân lương_tâm gia_đình chặng đường khắc_nghiệt chông gai. đừng rơi họ, đừng rơi nào. quan_sát câu mông cổ lãnh_đạo việt nam thăm thăm hoa kỳ, cuba. quan_sát giải mặt địa chiến_lược hai đường trái_ngược việt nam mông cổ liên xổ sụp đổ. vui ấm phái_đoàn hoà lan, bỉ, đức, thuỵ sĩ, mỹ quản_ngại đường xá xôi cộng_đồng việt pháp tiếng phản_đối án tô lâm, tổng bí_thư đảng csvn kiêm chủ_tịch nước, tội_nhân đàn_áp dã_man vụ án đồng_tâm bắt dân chủ, tiếng ôn hoà, đấu_tranh việt nam chế xã_hội nhân_công hơn, xây_dựng tảng do, dân_chủ_nhân quyền. việt tân tập_hợp việt yêu dân_chủ khát_vọng_canh_tân canh_tân việt nam hoạt_động đấu_tranh bất bạo động.\n",
      "-----------\n",
      "=>start: 510-end: 766\n",
      "=>segment: \n",
      "-----------\n",
      "=>start: 765-end: 1021\n",
      "=>segment: \n",
      "-----------\n",
      "=>start: 1020-end: 1024\n",
      "=>segment: \n",
      "-----------\n",
      "### Len encoding texts: 5 ###\n",
      "#idx: 0\n",
      "=>Encoding_text_input_ids: torch.Size([1, 256])\n",
      "=>Encoding_text_attention_masks: torch.Size([1, 256])\n",
      "Dự đoán thành công\n",
      "#idx: 1\n",
      "=>Encoding_text_input_ids: torch.Size([1, 256])\n",
      "=>Encoding_text_attention_masks: torch.Size([1, 256])\n",
      "Dự đoán thành công\n",
      "#idx: 2\n",
      "=>Encoding_text_input_ids: torch.Size([1, 256])\n",
      "=>Encoding_text_attention_masks: torch.Size([1, 256])\n",
      "Bỏ qua sub-text tại vị trí 2 vì input_ids toàn padding và attention_mask chủ yếu là 0\n",
      "#idx: 3\n",
      "=>Encoding_text_input_ids: torch.Size([1, 256])\n",
      "=>Encoding_text_attention_masks: torch.Size([1, 256])\n",
      "Bỏ qua sub-text tại vị trí 3 vì input_ids toàn padding và attention_mask chủ yếu là 0\n",
      "#idx: 4\n",
      "=>Encoding_text_input_ids: torch.Size([1, 256])\n",
      "=>Encoding_text_attention_masks: torch.Size([1, 256])\n",
      "Bỏ qua sub-text tại vị trí 4 vì input_ids toàn padding và attention_mask chủ yếu là 0\n",
      "average_outputs_text: tensor([[0.0327, 0.9528, 0.0146]]), shape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tạo dữ liệu mẫu\n",
    "content = \"23 9, 2010 kính gửi thủ_tướng nguyễn dũng cộng_hoà xã_hội chủ nghiã việt nam đại_sứ việt nam 1233 20th street, nw, suite 400 washington, dc 20036 thưa thủ tướng, mấy tuần cầm_quyền việt nam bắt giam vận_động dân chủ. giáo_sư_phạm minh hoàng, mục_sư dương kim khải, trần thị thuý nguyễn thành_tâm bắt giam đòi thay_đổi dân_chủ ôn_hoà thực_thi_nhân_quyền tham_gia hoạt_động trị tư thành_viên tổ_chức tranh_đấu dân_chủ đảng việt tân. giam lý nêu phi_lý thể chấp được. việt nam ký tuyên_ngôn quốc_tế nhân_quyền cầm_quyền việt nam tiếp_tục bắt sách_nhiễu trí thức, vị lãnh_đạo tôn_giáo_dân_chủ ôn_hoà quan tâm. dân_biểu quốc_hội hỗ_trợ rộng quan_hệ song_phương quyền tiếp_tục bóp_nghẹt thô_bạo quyền bày_tỏ bất_đồng kiến ôn_hoà dân nói, báo chí, mạng internet. tham_gia hoạt_động tranh_đấu ôn_hoà tội hình sự, quyền việt nam gán nhãn_hiệu bất hợp_pháp phi lý. cầm_quyền việt nam tiếp_tục đàn_áp dân quan tâm. bắt giam giáo_sư_phạm minh hoàng phản_đối khai_thác quặng mỏ bô-xít tây_nguyên viết đăng trang blog vô lý. quyền bạo_lực đối nguyễn thành_tâm trần thị thuý giúp nông_dân đòi công_xã_hội thể chấp nhận. kinh_hãi việt nam mục_sư dương kim khải tội_nhân ta thực_thi quyền tôn_giáo áp_dụng răn dậy tôn_giáo sống hàng giúp_đỡ nông_dân cướp ruộng_đất khiếu nại. cầm_quyền việt nam tiếp_tục biến quyền ngôn luận, quyền phát biểu, quyền hội_họp quyền tôn_giáo thành tội hình_thể chấp được. thể tiếp_tục thành_viên thực cộng_đồng giới, cầm_quyền việt nam ngưng sách_nhiễu đàn_áp dân phát_biểu ôn_hoà tham_gia hoạt_động trị. dân_biểu quốc_hội quan_tâm dạn thách_đố cầm_quyền việt nam phép tất công_dân_quyền phát_biểu phép tham_gia sinh_hoạt đấu tranh. kêu_gọi cầm_quyền việt nam lập_tức ngừng sách_nhiễu dân thả tù_nhân trị hiện giam phản_đối quyết_định cầm quyền. trân trọng, loretta sanchez dân_biểu quốc_hội joseph dân_biểu quốc_hội zoe lofgren dân_biểu quốc_hội dan burton dân_biểu quốc_hội gerald connolly dân_biểu quốc_hội daniel lungren dân_biểu quốc_hội david wu dân_biểu quốc_hội john culbertson dân_biểu quốc_hội judy chu dân_biểu quốc_hội james mcgovern dân_biểu quốc hội. cc: trưởng ngoại_giao hillary rodham clinton giới_chức việt nam tuyến đường_sắt tốc nối hà nội sài gòn tầm quan_trọng chiến_lược dự_đoán lợi_ích to kinh_tế xã hội, kiến băn_khoăn chi phí, khả_thi mặt thương_mại tác_động hạn_chế kinh tế. tù nghìn_thu ngoài. đi tù nghĩa câu ấy. nhà, hàng trăm em, bè ta mòn_mỏi tù. mong tiếp_tục đồng_hành giúp_đỡ tù_nhân lương_tâm gia_đình chặng đường khắc_nghiệt chông gai. đừng rơi họ, đừng rơi nào. quan_sát câu mông cổ lãnh_đạo việt nam thăm thăm hoa kỳ, cuba. quan_sát giải mặt địa chiến_lược hai đường trái_ngược việt nam mông cổ liên xổ sụp đổ. vui ấm phái_đoàn hoà lan, bỉ, đức, thuỵ sĩ, mỹ quản_ngại đường xá xôi cộng_đồng việt pháp tiếng phản_đối án tô lâm, tổng bí_thư đảng csvn kiêm chủ_tịch nước, tội_nhân đàn_áp dã_man vụ án đồng_tâm bắt dân chủ, tiếng ôn hoà, đấu_tranh việt nam chế xã_hội nhân_công hơn, xây_dựng tảng do, dân_chủ_nhân quyền. việt tân tập_hợp việt yêu dân_chủ khát_vọng_canh_tân canh_tân việt nam hoạt_động đấu_tranh bất bạo động. \"\n",
    "# Dự đoán\n",
    "probabilities = predict(content, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Thật': 0.03266631066799164,\n",
       " 'Giả do con người': 0.9527502655982971,\n",
       " 'Giả do AI': 0.014583307318389416}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm remove stopword\n",
    "def remove_stopwords(text:str):\n",
    "    # Load stopword\n",
    "    stop_words = []\n",
    "    with open('./checkpoints/vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "        stop_words = f.read().splitlines()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word.lower() for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Nguồn nhân lực chất lượng cao được tập trung phát triển, gắn với khoa học công nghệ, đổi mới sáng tạo, khởi nghiệp. Năm 2024, Việt Nam đứng thứ 3 ASEAN về đầu tư vào Start-up; thứ 56 thế giới, thứ 5 khu vực Đông Nam Á và thứ 12 khu vực châu Á - Thái Bình Dương về Chỉ số hệ sinh thái khởi nghiệp toàn cầu.\n",
    "\n",
    "Tỷ lệ thất nghiệp khu vực thành thị ước cả năm dưới 4%. Chính phủ cũng dành gần 700.000 tỷ đồng để tăng mức lương cơ sở lên 30% cho cán bộ, công chức, viên chức, lực lượng vũ trang. Lương hưu, bảo hiểm xã hội, trợ cấp ưu đãi người có công và trợ cấp xã hội từ ngày 1/7 được tăng với mức cao nhất từ trước đến nay.\n",
    "\n",
    "Tuy nhiên, Thủ tướng nhìn nhận kinh tế vĩ mô còn tiềm ẩn rủi ro từ lạm phát, tỷ giá. Tín dụng tăng trưởng chưa cao; áp lực trả nợ trái phiếu doanh nghiệp đến hạn lớn. Hoạt động sản xuất, kinh doanh gặp nhiều khó khăn. Sức mua trong nước có dấu hiệu tăng chậm lại.\n",
    "\n",
    "Thể chế, pháp luật còn một số vướng mắc. Việc phân cấp, phân quyền, cắt giảm một số quy định, thủ tục hành chính còn rườm rà, chưa triệt để. Chất lượng nguồn nhân lực, nhất là ngành công nghệ cao chưa đáp ứng yêu cầu. Đời sống của một bộ phận người dân còn khó khăn. Thiên tai, bão lũ diễn biến khó lường, nhất là cơn bão Yagi gây thiệt hại nghiêm trọng.\n",
    "\n",
    "Phương hướng những tháng cuối năm, Chính phủ chú trọng ưu tiên thúc đẩy tăng trưởng gắn với giữ vững ổn định kinh tế vĩ mô, kiểm soát lạm phát và bảo đảm các cân đối lớn của nền kinh tế, an ninh năng lượng, an ninh lương thực. Trong đó, tốc độ tăng GDP phấn đấu đạt khoảng 7%.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134998272"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "count_parameters(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(258, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
